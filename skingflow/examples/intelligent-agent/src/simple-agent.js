/**
 * Simplified Intelligent Agent System for Testing
 * 
 * @author skingko <venture2157@gmail.com>
 */

import { PostgresMemoryStorage } from './storage/postgres-adapter.js';
import config, { validateConfig } from './config.js';
import chalk from 'chalk';
import fetch from 'node-fetch';

/**
 * Simple Intelligent Agent Class
 */
export class SimpleIntelligentAgent {
  constructor() {
    this.memory = null;
    this.initialized = false;
  }

  async initialize() {
    if (this.initialized) return;

    console.log(chalk.blue('ğŸš€ Initializing Simple Agent System...\n'));

    try {
      // Validate configuration
      validateConfig();
      console.log(chalk.green('âœ… Configuration validated'));

      // Initialize memory storage
      this.memory = new PostgresMemoryStorage(config.memory.storage.config);
      await this.memory.initialize();
      console.log(chalk.green('âœ… Memory system initialized'));

      this.initialized = true;
      console.log(chalk.green('ğŸ‰ Simple Agent System initialized successfully!\n'));

    } catch (error) {
      console.error(chalk.red('âŒ Initialization failed:'), error.message);
      throw error;
    }
  }

  async processQuery(query, userId = 'default') {
    if (!this.initialized) {
      await this.initialize();
    }

    console.log(chalk.blue(`\nğŸ“ Processing query from ${userId}:`));
    console.log(chalk.white(`"${query}"\n`));

    try {
      // 1. Search memory
      console.log(chalk.blue('ğŸ§  Searching memory...'));
      const memories = await this.searchMemory(query, userId);
      console.log(chalk.green(`âœ… Found ${memories.length} relevant memories`));

      // 2. Generate response with LLM
      console.log(chalk.blue('ğŸ¤– Generating response...'));
      const response = await this.generateResponse(query, memories);
      console.log(chalk.green('âœ… Response generated'));

      // 3. Store interaction
      console.log(chalk.blue('ğŸ’¾ Storing interaction...'));
      await this.storeInteraction(query, response, userId);
      console.log(chalk.green('âœ… Interaction stored'));

      console.log(chalk.blue('\nğŸ¤– Agent Response:'));
      console.log('-'.repeat(50));
      console.log(response);
      console.log('-'.repeat(50));

      return {
        success: true,
        userId,
        query,
        response,
        memoriesFound: memories.length,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error(chalk.red('âŒ Query processing failed:'), error.message);
      throw error;
    }
  }

  async searchMemory(query, userId) {
    if (!this.memory) return [];

    try {
      // Simple text-based search
      const memories = await this.memory.query({
        build: () => ({
          conditions: [
            { type: 'semantic_search', text: query }
          ],
          sort: { field: 'importance', order: 'desc' },
          limit: 5,
          offset: 0
        })
      });

      return memories || [];
    } catch (error) {
      console.warn(chalk.yellow(`âš ï¸  Memory search failed: ${error.message}`));
      return [];
    }
  }

  async generateResponse(query, memories) {
    try {
      let prompt = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n`;
      
      if (memories.length > 0) {
        prompt += `ç›¸å…³è®°å¿†ï¼š\n`;
        memories.forEach((memory, index) => {
          prompt += `${index + 1}. ${memory.content}\n`;
        });
        prompt += `\n`;
      }
      
      prompt += `ç”¨æˆ·é—®é¢˜ï¼š${query}\n\nè¯·æä¾›æœ‰å¸®åŠ©çš„å›ç­”ï¼š`;

      const response = await fetch(`${config.llm.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.llm.apiKey}`
        },
        body: JSON.stringify({
          model: config.llm.model,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: config.llm.temperature,
          max_tokens: config.llm.maxTokens
        })
      });

      if (!response.ok) {
        throw new Error(`LLM API error: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      return data.choices[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›ç­”ã€‚';

    } catch (error) {
      console.warn(chalk.yellow(`âš ï¸  LLM generation failed: ${error.message}`));
      return `æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ï¼š"${query}"`;
    }
  }

  async storeInteraction(query, response, userId) {
    if (!this.memory) return;

    try {
      await this.memory.insert({
        content: `é—®é¢˜: ${query}\nå›ç­”: ${response}`,
        type: 'conversation',
        category: 'interaction',
        userId: userId,
        importance: 0.7,
        metadata: {
          timestamp: new Date().toISOString()
        }
      });
    } catch (error) {
      console.warn(chalk.yellow(`âš ï¸  Memory storage failed: ${error.message}`));
    }
  }

  async close() {
    if (this.memory) {
      await this.memory.close();
    }
    this.initialized = false;
    console.log(chalk.blue('ğŸ‘‹ Simple Agent System closed'));
  }
}

export default SimpleIntelligentAgent;
